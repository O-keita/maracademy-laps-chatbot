{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d3e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102cd874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/computer_science.json...\n",
      "Loaded 172 intents from /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/computer_science.json\n",
      "Loading /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/maracademy.json...\n",
      "Loaded 12 intents from /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/maracademy.json\n",
      "Loading /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/data_science.json...\n",
      "Loaded 31 intents from /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/data_science.json\n",
      "Total combined pairs: 519\n",
      "Sample pairs: [{'user': 'Explain data abstraction.', 'bot': 'Data abstraction is a technique used in computer programming to separate the implementation details of a data type from its interface, allowing the implementation to be changed without affecting the code that uses it. This is often achieved through the use of abstract data types (ADTs), which are defined by the operations they support rather than their specific implementation, or through the use of interfaces and classes in object-oriented programming languages. Data abstraction helps to reduce the complexity of software systems by allowing code to be written in a modular and flexible way and by hiding the underlying details of data types from the user.'}, {'user': 'What is data abstraction?', 'bot': 'Data abstraction is a technique used in computer programming to separate the implementation details of a data type from its interface, allowing the implementation to be changed without affecting the code that uses it. This is often achieved through the use of abstract data types (ADTs), which are defined by the operations they support rather than their specific implementation, or through the use of interfaces and classes in object-oriented programming languages. Data abstraction helps to reduce the complexity of software systems by allowing code to be written in a modular and flexible way and by hiding the underlying details of data types from the user.'}, {'user': 'Define data abstraction.', 'bot': 'Data abstraction is a technique used in computer programming to separate the implementation details of a data type from its interface, allowing the implementation to be changed without affecting the code that uses it. This is often achieved through the use of abstract data types (ADTs), which are defined by the operations they support rather than their specific implementation, or through the use of interfaces and classes in object-oriented programming languages. Data abstraction helps to reduce the complexity of software systems by allowing code to be written in a modular and flexible way and by hiding the underlying details of data types from the user.'}, {'user': 'What is a syntax error', 'bot': \"A syntax error is an error in the structure of a programming language's code. It occurs when the code does not conform to the rules of the programming language's syntax. Syntax errors can occur for a variety of reasons, such as using the wrong punctuation, omitting required elements, or using an incorrect keyword. Syntax errors are usually detected by a compiler or interpreter when the code is being compiled or executed, and they can prevent the code from running correctly. To fix a syntax error, the code must be revised to conform to the correct syntax of the programming language.\"}, {'user': 'Explain syntax error', 'bot': \"A syntax error is an error in the structure of a programming language's code. It occurs when the code does not conform to the rules of the programming language's syntax. Syntax errors can occur for a variety of reasons, such as using the wrong punctuation, omitting required elements, or using an incorrect keyword. Syntax errors are usually detected by a compiler or interpreter when the code is being compiled or executed, and they can prevent the code from running correctly. To fix a syntax error, the code must be revised to conform to the correct syntax of the programming language.\"}]\n",
      "Combined Q&A pairs saved to /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/conversations_combined.csv\n"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "\"\"\"\n",
    "    lets convert our json to csv\n",
    "    convert json into csv of in the format of User, Bot\n",
    "    for all the json documents we have and combine themm\n",
    "\"\"\"\n",
    "#=================================================\n",
    "\n",
    "!python ../scripts/json_to_csv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab65ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/preprocess.py:40: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df['user'] = df['user'].str.replace('\\s+', ' ', regex=True)\n",
      "/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/preprocess.py:41: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df['bot'] = df['bot'].str.replace('\\s+', ' ', regex=True)\n",
      "Preprocessed data saved to /home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/notebook/../scripts/../data/conversations_clean.csv\n"
     ]
    }
   ],
   "source": [
    "#==========================================\n",
    "#preprocess our data\n",
    "#we import our preprocess model from preprcess\n",
    "#==========================================\n",
    "\n",
    "\n",
    "!python ../scripts/preprocess.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b07075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27124c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV successfully converted to txt corpus\n"
     ]
    }
   ],
   "source": [
    "#==============================================\n",
    "\"\"\"\n",
    "    now we convert the csv to a txt containing corpus\n",
    "    Bot:...............\n",
    "    User:..............\n",
    "\"\"\"\n",
    "#===============================================\n",
    "!python ../scripts/csv_pretrained.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49537fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-16 16:39:36.916199: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-16 16:39:36.956512: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-16 16:39:37.940897: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/2920 [00:00<?, ?it/s]/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "{'loss': 2.2238, 'grad_norm': 16.058212280273438, 'learning_rate': 4.830479452054795e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7332, 'grad_norm': 10.876388549804688, 'learning_rate': 4.6592465753424655e-05, 'epoch': 1.37}\n",
      "{'loss': 1.4728, 'grad_norm': 8.341639518737793, 'learning_rate': 4.4880136986301375e-05, 'epoch': 2.05}\n",
      "{'loss': 1.1939, 'grad_norm': 8.958134651184082, 'learning_rate': 4.316780821917809e-05, 'epoch': 2.74}\n",
      "{'loss': 1.0029, 'grad_norm': 10.823430061340332, 'learning_rate': 4.1455479452054795e-05, 'epoch': 3.42}\n",
      " 20%|███████▌                              | 584/2920 [17:53<1:09:18,  1.78s/it]/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 0.8437, 'grad_norm': 8.206233978271484, 'learning_rate': 3.974315068493151e-05, 'epoch': 4.11}\n",
      "{'loss': 0.6878, 'grad_norm': 8.933398246765137, 'learning_rate': 3.803082191780822e-05, 'epoch': 4.79}\n",
      "{'loss': 0.5655, 'grad_norm': 6.911395072937012, 'learning_rate': 3.6318493150684934e-05, 'epoch': 5.48}\n",
      "{'loss': 0.4984, 'grad_norm': 6.546276569366455, 'learning_rate': 3.460616438356165e-05, 'epoch': 6.16}\n",
      "{'loss': 0.418, 'grad_norm': 4.576390743255615, 'learning_rate': 3.2893835616438354e-05, 'epoch': 6.85}\n",
      " 35%|████████████▉                        | 1022/2920 [30:45<1:00:02,  1.90s/it]/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 0.3452, 'grad_norm': 3.919118881225586, 'learning_rate': 3.118150684931507e-05, 'epoch': 7.53}\n",
      "{'loss': 0.3172, 'grad_norm': 4.759200096130371, 'learning_rate': 2.9469178082191783e-05, 'epoch': 8.22}\n",
      "{'loss': 0.2731, 'grad_norm': 5.258312702178955, 'learning_rate': 2.7756849315068496e-05, 'epoch': 8.9}\n",
      "{'loss': 0.2268, 'grad_norm': 4.768576622009277, 'learning_rate': 2.6044520547945206e-05, 'epoch': 9.59}\n",
      "{'loss': 0.21, 'grad_norm': 4.562700271606445, 'learning_rate': 2.433219178082192e-05, 'epoch': 10.27}\n",
      "{'loss': 0.2131, 'grad_norm': 4.7971272468566895, 'learning_rate': 2.261986301369863e-05, 'epoch': 10.96}\n",
      " 55%|█████████████████████▍                 | 1606/2920 [48:08<31:34,  1.44s/it]/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 0.1705, 'grad_norm': 3.8998000621795654, 'learning_rate': 2.0907534246575346e-05, 'epoch': 11.64}\n",
      "{'loss': 0.1616, 'grad_norm': 3.522139072418213, 'learning_rate': 1.9195205479452055e-05, 'epoch': 12.33}\n",
      "{'loss': 0.1594, 'grad_norm': 3.610503673553467, 'learning_rate': 1.748287671232877e-05, 'epoch': 13.01}\n",
      "{'loss': 0.1331, 'grad_norm': 3.1427299976348877, 'learning_rate': 1.577054794520548e-05, 'epoch': 13.7}\n",
      " 70%|█████████████████████████▉           | 2044/2920 [1:00:31<20:54,  1.43s/it]/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 0.1282, 'grad_norm': 2.805028200149536, 'learning_rate': 1.4058219178082193e-05, 'epoch': 14.38}\n",
      "{'loss': 0.1189, 'grad_norm': 3.1646728515625, 'learning_rate': 1.2345890410958904e-05, 'epoch': 15.07}\n",
      "{'loss': 0.1164, 'grad_norm': 3.2955336570739746, 'learning_rate': 1.0633561643835618e-05, 'epoch': 15.75}\n",
      "{'loss': 0.1103, 'grad_norm': 2.5007708072662354, 'learning_rate': 8.921232876712329e-06, 'epoch': 16.44}\n",
      "{'loss': 0.1069, 'grad_norm': 1.875935673713684, 'learning_rate': 7.208904109589042e-06, 'epoch': 17.12}\n",
      "{'loss': 0.0999, 'grad_norm': 3.975844621658325, 'learning_rate': 5.496575342465754e-06, 'epoch': 17.81}\n",
      " 90%|█████████████████████████████████▎   | 2628/2920 [1:16:54<08:10,  1.68s/it]/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 91%|█████████████████████████████████▌   | 2646/2920 [1:17:22<07:48,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "#===========================================\n",
    "#train model\n",
    "#============================================\n",
    "\n",
    "!python ../scripts/train_gpt2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fb73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar-keita/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-16 16:34:38.166830: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-16 16:34:38.217454: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-16 16:34:39.321909: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for '../models/gpt2-finetuned-maracademy'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '../models/gpt2-finetuned-maracademy' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../models/gpt2-finetuned-maracademy'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1993\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   1992\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2003\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2004\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2005\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2006\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2007\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2008\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   2009\u001b[39m     \u001b[38;5;66;03m# Re-raise any error raised by cached_file in order to get a helpful error message\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03mTries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/utils/hub.py:532\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m    531\u001b[39m resolved_files = [\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    534\u001b[39m ]\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/utils/hub.py:143\u001b[39m, in \u001b[36m_get_cache_file_to_return\u001b[39m\u001b[34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cache_file_to_return\u001b[39m(\n\u001b[32m    136\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    137\u001b[39m     full_filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m ):\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     resolved_file = \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file != _CACHED_NO_EXIST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../models/gpt2-finetuned-maracademy'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Update the path below to wherever your fine-tuned model is saved\u001b[39;00m\n\u001b[32m      4\u001b[39m model_dir = \u001b[33m\"\u001b[39m\u001b[33m../models/gpt2-finetuned-maracademy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m tokenizer = \u001b[43mGPT2Tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai+ml/alu/maracademy-laps-chatbot/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2013\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2010\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   2011\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   2012\u001b[39m     \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2013\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m   2014\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt load tokenizer for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. If you were trying to load it from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2015\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, make sure you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have a local directory with the same name. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2016\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOtherwise, make sure \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is the correct path to a directory \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2017\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokenizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2018\u001b[39m     )\n\u001b[32m   2020\u001b[39m commit_hash = extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[32m   2021\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOSError\u001b[39m: Can't load tokenizer for '../models/gpt2-finetuned-maracademy'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '../models/gpt2-finetuned-maracademy' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Update the path below to wherever your fine-tuned model is saved\n",
    "model_dir = \"../models/gpt2-finetuned-maracademy\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "prompt = \"User: who is omar keita\\nBot:\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774536b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
